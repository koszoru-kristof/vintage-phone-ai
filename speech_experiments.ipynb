{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-AI based chat serivce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an AI, so I don't have feelings, but I'm here to help you!\n"
     ]
    }
   ],
   "source": [
    "print(get_completion(\"How are you today? answer in a few words.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_transcript(audio_file_path):\n",
    "    audio_file = open(audio_file_path, \"rb\")\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=audio_file, \n",
    "    response_format=\"text\"\n",
    "    )\n",
    "    return transcript\n",
    "\n",
    "def text_to_speech(text, output_file_path, voice=\"alloy\"):\n",
    "    response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=voice,\n",
    "        input=text\n",
    "    )\n",
    "    response.stream_to_file(output_file_path)\n",
    "    return output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"Hello, how are you?\"\n",
    "text_to_speech(test_sentence, \"recordings/assistant/audio.mp3\")\n",
    "\n",
    "get_transcript(\"recordings/assistant/audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(file_name, duration=5, rate=44100, chunk=1024, format=pyaudio.paInt16, channels=1):\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format=format,\n",
    "                        channels=channels,\n",
    "                        rate=rate,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=chunk)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    wave_file = wave.open(file_name, 'wb')\n",
    "    wave_file.setnchannels(channels)\n",
    "    wave_file.setsampwidth(audio.get_sample_size(format))\n",
    "    wave_file.setframerate(rate)\n",
    "    wave_file.writeframes(b''.join(frames))\n",
    "    wave_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_audio(\"audio.wav\", duration=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.front\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround40\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround41\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround50\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround51\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2666:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm_dmix.c:999:(snd_pcm_dmix_open) unable to open slave\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "user: This is the last experiment I'm doing today.\n",
      "\n",
      "assistant: I have completed all the experiments scheduled for today, and this is the final one.\n"
     ]
    }
   ],
   "source": [
    "# Let's put it all together\n",
    "# First, we'll record audio to a file\n",
    "# Then, we'll transcribe the audio\n",
    "# Finally, we'll send the transcript to the LLM\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "from playsound import playsound\n",
    "\n",
    "\n",
    "# Get the current time\n",
    "current_time = datetime.datetime.now()\n",
    "\n",
    "# Format the current time as a string\n",
    "filename = current_time.strftime(\"%Y%m%d-%H%M%S\") + \".wav\"\n",
    "dir = \"recordings/user\"\n",
    "rec_full_path = os.path.join(dir, filename)\n",
    "\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "\n",
    "dir_assistant = \"recordings/assistant\"\n",
    "if not os.path.exists(dir_assistant):\n",
    "    os.makedirs(dir_assistant)\n",
    "\n",
    "# Record audio to the file\n",
    "record_audio(rec_full_path, duration=5)\n",
    "\n",
    "# Transcribe the audio\n",
    "user_query_text = get_transcript(rec_full_path)\n",
    "print(\"user:\", user_query_text)\n",
    "\n",
    "# Send it to the LLM see what it says\n",
    "response_assistant_text = get_completion(user_query_text)\n",
    "print(\"assistant:\", response_assistant_text)\n",
    "\n",
    "# Convert the response to speech\n",
    "response_assitant_filename = current_time.strftime(\"%Y%m%d-%H%M%S\") + \".mp3\"\n",
    "response_assistant_full_path = os.path.join(dir_assistant, response_assitant_filename)\n",
    "\n",
    "audio_response_assistant = text_to_speech(response_assistant_text, response_assistant_full_path)\n",
    "\n",
    "# Play the response\n",
    "playsound(audio_response_assistant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
